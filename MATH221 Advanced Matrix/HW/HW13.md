- Consider the same slight variation on the 2D Model Problem, T(a,b), defined in last week's homework.
    
    - Is there an ordering of the equations and unknowns for which SOR(w) converges, for T(a,b), for some values of w? What ordering, and which values of w?




    - What value w_opt minimizes rho(R_SOR(w))? What is the value of rho(R_SOR(w_opt))?
    
- Question 6.15, parts 1 and 2
- Extra Credit: Question 6.15, part 3

![[Pasted image 20231128191255.png]]

![[Pasted image 20231128191353.png]]

We have that
$$P_{i}^{i-1}=\begin{bmatrix}1/4 & 1/2 & 1/4 \\   &     & 1/4 & 1/2  & 1/4 \\  &   & & \ddots  & \ddots  & \ddots  \\  &    &   &   & & 1/4 & 1/2 & 1/4\end{bmatrix}, \qquad P_{i-1}^{i}=\begin{bmatrix}1/2 \\ 1 \\ 1/2  & 1/2 \\  & 1 & \ddots  \\  & 1/2 & \ddots  & 1/2 \\  &   & \ddots  & 1 \\  &   &   &  1/2\end{bmatrix}.$$
Let's compute the matrix multiplications,
$$\begin{align*}
4P^{i-1}_{i}T^{(i)}P_{i-1}^{i}&= \begin{bmatrix}1/2 & 1 & 1/2 \\   &     & 1/2 & 1  & 1/2 \\  &   & & \ddots  & \ddots  & \ddots  \\  &    &   &   & & 1/2 & 1 & 1/2\end{bmatrix}\begin{bmatrix} 2 & -1\\
-1 & 2 & -1\\
 & \ddots  & \ddots  & \ddots \\
 &   &   -1 & 2 \end{bmatrix} \begin{bmatrix}1 \\ 2 \\ 1  & 1 \\  & 2 & \ddots  \\  & 1 & \ddots  & 1 \\  &   & \ddots  & 2 \\  &   &   &  1\end{bmatrix}\\
&= \begin{bmatrix}1/2 & 1 & 1/2 \\   &     & 1/2 & 1  & 1/2 \\  &   & & \ddots  & \ddots  & \ddots  \\  &    &   &   & & 1/2 & 1 & 1/2\end{bmatrix}\begin{bmatrix}0 & \dots  & \dots  & 0\\
2 & -1\\
0 & \dots & \dots  & 0 \\
-1 & 2 & -1\\
0 & \dots & \dots  & 0 \\
0 & -1 & 2 & -1\\
\vdots  & \vdots  & \vdots  & \vdots \\
0 & 0 & -1 & 2\\
0 & \dots  & \dots  & 0\end{bmatrix}
\end{align*}$$
where in the last matrix we have an alternating pattern between zero rows and rows with $-1,2,-1$. This arises since row number $j$ in the resulting matrix is $2 \cdot$ row $j$ - row $j-1$ - row $j+1$ in $P_{i-1}^{i}$.

Finally, we see that 
$$\begin{bmatrix}1/2 & 1 & 1/2 \\   &     & 1/2 & 1  & 1/2 \\  &   & & \ddots  & \ddots  & \ddots  \\  &    &   &   & & 1/2 & 1 & 1/2\end{bmatrix}\begin{bmatrix}0 & \dots  & \dots  & 0\\
2 & -1\\
0 & \dots & \dots  & 0 \\
-1 & 2 & -1\\
0 & \dots & \dots  & 0 \\
0 & -1 & 2 & -1\\
\vdots  & \vdots  & \vdots  & \vdots \\
0 & 0 & -1 & 2\\
0 & \dots  & \dots  & 0\end{bmatrix}=\begin{bmatrix} 2 & -1\\
-1 & 2 & -1\\
 & \ddots  & \ddots  & \ddots \\
 &   &   -1 & 2 \end{bmatrix}=T^{(i-1)}$$
 since we are again taking a weighted average of the rows, but now row number $j$ is comprised of row $2j$ - row $2j-1$ - row $2j+1$ in the second matrix. Since rows $2j\pm1$ are zero rows, we only take row $2j$.

Note that $P_{i-1}^{i}=2(P_{i}^{i-1})^{T}$, then we get the last equality
$$T^{(i-1)}=4P^{i-1}_{i}T^{(i)}P_{i-1}^{i}=4P^{i-1}_{i}T^{(i)}2(P_{i}^{i-1})^{T}=8P^{i-1}_{i}T^{(i)}(P_{i}^{i-1})^{T}$$

![[Pasted image 20231128191410.png]]

![[Pasted image 20231128191427.png]]
